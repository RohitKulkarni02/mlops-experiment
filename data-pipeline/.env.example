# Copy to .env and run: bash setup.sh
# Required by Airflow Docker (see https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)

# Linux/Mac: run "echo -e \"AIRFLOW_UID=$(id -u)\" >> .env" or let setup.sh create it
AIRFLOW_UID=50000

# Shared credentials (same for whole team when using Docker; change for production)
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow

# Optional: project dir for volume mounts (defaults to current directory)
# AIRFLOW_PROJ_DIR=/path/to/data-pipeline

# Optional: extra pip packages (space-separated; default includes pandas, numpy, soundfile, etc.)
# _PIP_ADDITIONAL_REQUIREMENTS=pandas numpy scipy soundfile librosa pyyaml great-expectations requests tqdm checksumdir
